# This is a basic workflow to help you get started with Actions

name: Provision and Configure Azure Infrastructure

# Controls when the workflow will run
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:

  Infrastructure_Provisioning:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    permissions: write-all


    
    # Set the working directory to main for the config files
    defaults:
      run:
        shell: bash
        working-directory: /home/runner/work/azml-aks-online-endpoint/

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

          # Install packages
      - name: Install required packages.
        run: sudo apt-get update && sudo apt-get install unzip -y && sudo apt-get install vim -y && sudo apt-get install python3 -y &&  sudo apt-get install jq -y && sudo apt-get install -y gettext-base && sudo apt-get install npm -y && curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash && sudo az aks install-cli | sudo bash
      
      - name: Install Python dependencies
        run: |
          pip install azure-functions
          pip install azure-identity
          pip install azure-ai-ml

      #- name: Download data set for AZML Model 2
      #  working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/
      #  run: |
      #       wget https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip
      #       unzip odFridgeObjects.zip

        
      - name: Generate runner url from secret
        run: |
            export gh_runner_url="https://api.github.com/repos/${{ github.repository }}/actions/runners/registration-token"
            echo "GH_runner_url=$gh_runner_url" >> $GITHUB_ENV


      - name: Generate runner registration token 
        run: |
            export token="$(curl -L   -X POST   -H "Accept: application/vnd.github+json"   -H "Authorization: Bearer ${{ secrets.GH_PAT }} "  -H "X-GitHub-Api-Version: 2022-11-28" $GH_runner_url | jq -r .token)"
            echo "GH_runner_token=$token" >> $GITHUB_ENV
     

      - name: Azure Login
        uses: Azure/login@v1
        with:
          creds: '{"clientId":"${{ secrets.AZURE_CLIENT_ID }}","clientSecret":"${{ secrets.AZURE_CLIENT_SECRET }}","subscriptionId":"${{ secrets.SUBSCRIPTION_ID }}","tenantId":"${{ secrets.AZURE_TENANT_ID }}"}'
    
      #- name: Create Service Principal & Set ENV Vars
      #  env:
      #    RESOURCE_GROUP: azml-aks-online-endpoint-rg
      #    SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
      #  run: |
      #    az ad sp create-for-rbac --name azml-data-upload-sp --role contributor --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP >> tmp.txt
      #    export AZURE_CLIENT_SECRET="$(cat tmp.txt | jq -r .password)"
      #    export AZURE_CLIENT_ID="$(cat tmp.txt | jq -r .appId)"
      #    export AZURE_TENANT_ID="$(cat tmp.txt | jq -r .tenant)"
      #    echo "AZURE_CLIENT_SECRET=$AZURE_CLIENT_SECRET" >> $GITHUB_ENV
      #    echo "AZURE_CLIENT_ID=$AZURE_CLIENT_ID" >> $GITHUB_ENV
      #    echo "AZURE_TENANT_ID=$AZURE_TENANT_ID" >> $GITHUB_ENV

      - name: Create Resource Group
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
            az group create --name $RESOURCE_GROUP --location eastus

      - name: Register Microsoft Event Grid
        run: |
          az provider register --namespace Microsoft.EventGrid

      - name: Create infrerence storage account
        env:
          ENDPOINT_NAME: azml-aks-online-endpoint
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
        run: |
            az storage account create \
            --name inferenceupload \
            --resource-group $RESOURCE_GROUP \
            --location eastus 


      - name: Create VNET and Subnet
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
        
          az network vnet create --resource-group $RESOURCE_GROUP --name azml-aks-online-endpoint-vnet
          az network nsg create --resource-group $RESOURCE_GROUP --name azml-aks-online-endpoint-nsg
          az network vnet subnet create  --resource-group $RESOURCE_GROUP --name azml-aks-online-endpoint-subnet --vnet-name azml-aks-online-endpoint-vnet  --address-prefixes 10.0.0.0/22 --network-security-group azml-aks-online-endpoint-nsg

      - name: Get runner IP address
        run: |
            export runner_ip="$(curl -s https://api.ipify.org)"
            echo "runner_ip=$runner_ip" >> $GITHUB_ENV

      - name: Create AKS Cluster
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
         SUBNET=$(az network vnet subnet list --resource-group $RESOURCE_GROUP --vnet-name azml-aks-online-endpoint-vnet --query "[?name=='azml-aks-online-endpoint-subnet'].id" --output tsv)
         az aks create \
          --resource-group $RESOURCE_GROUP \
          --name azml-aks-online-endpoint-cluster \
          --load-balancer-sku standard \
          --network-plugin azure \
          --vnet-subnet-id $SUBNET \
          --dns-service-ip 10.2.0.10 \
          --service-cidr 10.2.0.0/24 \
          --enable-managed-identity \
          --generate-ssh-keys \
          --api-server-authorized-ip-ranges $runner_ip \
          --node-vm-size standard_DS3_v2

      - name: Get KubeConfig
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: az aks get-credentials -g $RESOURCE_GROUP  -n azml-aks-online-endpoint-cluster --overwrite-existing --admin


      - name: Create AZML K8s namespace
        run: kubectl create namespace azml-aks-online-endpoint-ns
      
        
      - name: Install AZ ML CLI Extenstion 
        run: |
            curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash 
            az extension add -n ml -y

      - name: Setup AZML workspace
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          LOCATION: eastus 
        run: |
            az ml workspace create -n $WORKSPACE -g $RESOURCE_GROUP -l $LOCATION
            az configure --defaults group=$RESOURCE_GROUP workspace=$WORKSPACE location=$LOCATION

      - name: Clone model training repository
        run: |
            git clone --depth 1 https://github.com/Azure/azureml-examples
            

      - name: Create JSONL file from downloaded data
        env: 
          AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/
        run: |
          python ./data/jsontojsonl.py --subscription $SUBSCRIPTION_ID --group $RESOURCE_GROUP --workspace $WORKSPACE --data_path ./odFridgeObjects

     
      - name: Create training managed compute - CPU Cluster
        run: |
            az ml compute create -n cpu-cluster --type amlcompute --min-instances 0 --max-instances 4
    
      - name: Create training managed compute - GPU Instance
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/compute
        run: |
            az ml compute create -f gpucompute.yaml  --workspace-name $WORKSPACE --resource-group $RESOURCE_GROUP --subscription $SUBSCRIPTION_ID
    
      - name: Train example model 1
        working-directory: /home/runner/work/azml-aks-online-endpoint/azureml-examples/cli/
        run: |
           export run_id=$(az ml job create -f jobs/single-step/scikit-learn/iris/job.yml --query name -o tsv)
           echo "run_id=$run_id" >> $GITHUB_ENV

      - name: Wait for model 1 job to finish
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export jobstatus=$(az ml job show --name $run_id --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          until [ "$jobstatus" = "Completed" ]; do
            echo "Waiting for job to finish"
            sleep 10
            export jobstatus=$(az ml job show --name $run_id --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          done

      - name: Register model 1
        run: |
          az ml model create -n sklearn-iris-example -v 1 -p runs:/$run_id/model --type mlflow_model

      - name: Train model 2
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/
        run: |
            export run_id_2=$(az ml job create --file ./jobs/automl_automode.yaml --workspace-name $WORKSPACE --resource-group $RESOURCE_GROUP --subscription $SUBSCRIPTION_ID --output json | jq -r .display_name) 
            echo "run_id_2=$run_id_2" >> $GITHUB_ENV

      - name: Wait for model 2 job to finish
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export jobstatus=$(az ml job show --name $run_id_2 --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          until [ "$jobstatus" = "Completed" ]; do
            echo "Waiting for job to finish"
            sleep 10
            export jobstatus=$(az ml job show --name $run_id_2 --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          done

      - name: Register model 2
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
          az ml model create -n fridge-items-mlflow-model -v 1 -p runs:/$run_id_2/mlflow-model --type mlflow_model --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --subscription $SUBSCRIPTION_ID


      - name: Add preview extension
        run: |
          az extension add --name aks-preview
          az extension update --name aks-preview

      - name: Register and install the GPU Extenstion
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
           az feature register --namespace "Microsoft.ContainerService" --name "GPUDedicatedVHDPreview"
           az provider register --namespace Microsoft.ContainerService

      - name: Register and install the Azure ML extension
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
           az k8s-extension create --name azml-aks-online --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer allowInsecureConnections=True InferenceRouterHA=False --cluster-type managedClusters --cluster-name azml-aks-online-endpoint-cluster --resource-group $RESOURCE_GROUP --scope cluster

      
      - name: Create AZML K8s instance types CRDS 
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/kubernetes_config
        run: kubectl apply -f instance_types.yaml 
     
      - name: Create GPU Nodepool for Model 1
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
         az aks nodepool add \
         --resource-group $RESOURCE_GROUP \
         --cluster-name azml-aks-online-endpoint-cluster \
         --name gpumodel1 \
         --node-count 1 \
         --node-vm-size standard_nc4as_t4_v3  \
         --labels gpu=yes costcenter=5000 model=model1 \
         --aks-custom-headers UseGPUDedicatedVHD=true \
         --enable-cluster-autoscaler \
         --min-count 1 \
         --max-count 3

      - name: Create GPU Nodepool for Model 2
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
         az aks nodepool add \
         --resource-group $RESOURCE_GROUP \
         --cluster-name azml-aks-online-endpoint-cluster \
         --name gpumodel2 \
         --node-count 1 \
         --node-vm-size standard_nc4as_t4_v3  \
         --labels gpu=yes costcenter=6000 model=model2 \
         --aks-custom-headers UseGPUDedicatedVHD=true \
         --enable-cluster-autoscaler \
         --min-count 1 \
         --max-count 3

      - name: Attatch cluster to ML Workspace
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
         az ml compute attach --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --type Kubernetes --name azml-aks-attatch --resource-id "/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.ContainerService/managedclusters/azml-aks-online-endpoint-cluster" --identity-type SystemAssigned --namespace azml-aks-online-endpoint-ns --no-wait
      
      - name: Create ML Endpoint for model 1 with AKS backend
        env:
          ENDPOINT_NAME: azml-aks-online-endpoint-model1
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/endpoint/
        run: |
          az ml online-endpoint create --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --name $ENDPOINT_NAME -f model1_endpoint_config.yaml
          az ml online-deployment create --name blue --endpoint $ENDPOINT_NAME -f model1_kubernetes_deployment.yaml --all-traffic --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE

      - name: Create ML Endpoint for model 1 with AKS backend
        env:
          ENDPOINT_NAME: azml-aks-online-endpoint-model2
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/endpoint/
        run: |
          az ml online-endpoint create --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --name $ENDPOINT_NAME -f model2_endpoint_config.yaml
          az ml online-deployment create --name blue --endpoint $ENDPOINT_NAME -f model2_kubernetes_deployment.yaml --all-traffic --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE
       
      - name: Create function storage account
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export functionstorage="funcstorage$RANDOM"
          echo "functionstorage=$functionstorage" >> $GITHUB_ENV
          az storage account create --name $functionstorage --location useast --resource-group $RESOURCE_GROUP --sku Standard_LRS --kind StorageV2  --allow-blob-public-access true
    
      - name: Create Azure Function
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          az functionapp create --name azml-function-app-inference --storage-account $functionstorage --resource-group $RESOURCE_GROUP --consumption-plan-location useast
      
      - name: Configure function app storage
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          storageConnectionString=$(az storage account show-connection-string --resource-group $RESOURCE_GROUP --name inferenceupload  --query connectionString --output tsv)
          az functionapp config appsettings set --name azml-function-app-inference --resource-group $RESOURCE_GROUP --settings AzureWebJobsStorage=$storageConnectionString FUNCTIONS_EXTENSION_VERSION=~2 FUNCTIONS_WORKER_RUNTIME=dotnet
     
      - name: Create the Service Bus
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          az servicebus namespace create --resource-group $RESOURCE_GROUP --name azmlaksonlineendpointbus --location eastus --mi-system-assigned
          az servicebus queue create --resource-group $RESOURCE_GROUP --namespace-name azmlaksonlineendpointbus --name azmlaksonlineendpointbusq
       
      - name: Create storage for DLQ
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          storageAccountName: azmlaksonlinedlq 
        run: |
            az storage account create \
             --name $storageAccountName \
             --resource-group $RESOURCE_GROUP \
            --query id \
            --output tsv 1>/dev/null

            echo "Retrieving the primary key of the [$storageAccountName] storage account..."
            export storageAccountKey=$(az storage account keys list \
             --account-name $storageAccountName \
            --resource-group $resourceGroupName \
            --query [0].value -o tsv)
              az storage container create \
             --name azmldlq \
             --account-name $storageAccountName \
              --account-key $storageAccountKey \
            --query id \
            --output tsv 1>/dev/null

      - name: Create eventgrid subscription 
        env: 
         RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export subjectEndsWith="${tenant,,}"
          export storageAccountId=$(az storage account show \
            --name $storageAccountName \
            --resource-group $resourceGroupName \
            --query id \
            --output tsv 2>/dev/null)

          export serviceBusId=$(az servicebus queue show \
            --name $serviceBusQueueName \
            --namespace-name azmlaksonlineendpointbus \
           --resource-group $RESOURCE_GROUP \
            --query id \
            --output tsv)

          az eventgrid event-subscription create \
            --endpoint-type servicebusqueue \
            --endpoint $serviceBusId \
            --deadletter-endpoint ${storageAccountId}/blobServices/default/containers/azmldlq \
            --name $eventGridSubscriptionName \
            --subject-ends-with $subjectEndsWith \
            --source-resource-id $resourceId 1>/dev/null

      - name: Create system topic for Azure Storage account
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          storageid=$(az storage account show --name inferenceupload --resource-group $RESOURCE_GROUP --query id --output tsv) 
          az eventgrid system-topic create \
          -g $RESOURCE_GROUP \
          --name inference-storage-topic\
          --location useast \
          --topic-type microsoft.storage.storageaccounts \
          --source $storageid
     
     
      - name: Create eventgrid subscription to push to queue 
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
          az eventgrid event-subscription create --name azml-aks-online-es1 \
          --system-topic-name  \
          --endpoint /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/namespaces/azmlaksonlineendpointbus/

      - name: Create COSMOS output table
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          az cosmosdb database create --name azml-aks-online-endpoint-output-db --resource-group $RESOURCE_GROUP --db-name model2output
      
# Create function that is triggered by event hub or service bus
# Create code for function that calls AZML API and uploads result to Cosmos DB
