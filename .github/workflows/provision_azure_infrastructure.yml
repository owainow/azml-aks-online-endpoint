# This is a basic workflow to help you get started with Actions

name: Provision and Configure Azure Infrastructure

# Controls when the workflow will run
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:

  Infrastructure_Provisioning:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    permissions: write-all


    
    # Set the working directory to main for the config files
    defaults:
      run:
        shell: bash
        working-directory: /home/runner/work/azml-aks-online-endpoint/

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3

          # Install packages
      - name: Install required packages.
        run: sudo apt-get update && sudo apt-get install unzip -y && sudo apt-get install vim -y && sudo apt-get install python3 -y &&  sudo apt-get install jq -y && sudo apt-get install -y gettext-base && sudo apt-get install npm -y && curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash && sudo az aks install-cli | sudo bash
      
      - name: Install Python dependencies
        run: |
          pip install azure-functions
          pip install azure-identity
          pip install azure-ai-ml

      #- name: Download data set for AZML Model 2
      #  working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/
      #  run: |
      #       wget https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip
      #       unzip odFridgeObjects.zip

        
      - name: Generate runner url from secret
        run: |
            export gh_runner_url="https://api.github.com/repos/${{ github.repository }}/actions/runners/registration-token"
            echo "GH_runner_url=$gh_runner_url" >> $GITHUB_ENV


      - name: Generate runner registration token 
        run: |
            export token="$(curl -L   -X POST   -H "Accept: application/vnd.github+json"   -H "Authorization: Bearer ${{ secrets.GH_PAT }} "  -H "X-GitHub-Api-Version: 2022-11-28" $GH_runner_url | jq -r .token)"
            echo "GH_runner_token=$token" >> $GITHUB_ENV
     

      - name: Azure Login
        uses: Azure/login@v1
        with:
          creds: '{"clientId":"${{ secrets.AZURE_CLIENT_ID }}","clientSecret":"${{ secrets.AZURE_CLIENT_SECRET }}","subscriptionId":"${{ secrets.SUBSCRIPTION_ID }}","tenantId":"${{ secrets.AZURE_TENANT_ID }}"}'
    
      #- name: Create Service Principal & Set ENV Vars
      #  env:
      #    RESOURCE_GROUP: azml-aks-online-endpoint-rg
      #    SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
      #  run: |
      #    az ad sp create-for-rbac --name azml-data-upload-sp --role contributor --scopes /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP >> tmp.txt
      #    export AZURE_CLIENT_SECRET="$(cat tmp.txt | jq -r .password)"
      #    export AZURE_CLIENT_ID="$(cat tmp.txt | jq -r .appId)"
      #    export AZURE_TENANT_ID="$(cat tmp.txt | jq -r .tenant)"
      #    echo "AZURE_CLIENT_SECRET=$AZURE_CLIENT_SECRET" >> $GITHUB_ENV
      #    echo "AZURE_CLIENT_ID=$AZURE_CLIENT_ID" >> $GITHUB_ENV
      #    echo "AZURE_TENANT_ID=$AZURE_TENANT_ID" >> $GITHUB_ENV

      - name: Create Resource Group
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
            az group create --name $RESOURCE_GROUP --location eastus

      - name: Register Microsoft Event Grid
        run: |
          az provider register --namespace Microsoft.EventGrid

      - name: Create infrerence storage account
        env:
          ENDPOINT_NAME: azml-aks-online-endpoint
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
        run: |
            az storage account create \
            --name inferenceupload \
            --resource-group $RESOURCE_GROUP \
            --location eastus 


      - name: Create VNET and Subnet
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
        
          az network vnet create --resource-group $RESOURCE_GROUP --name azml-aks-online-endpoint-vnet
          az network nsg create --resource-group $RESOURCE_GROUP --name azml-aks-online-endpoint-nsg
          az network vnet subnet create  --resource-group $RESOURCE_GROUP --name azml-aks-online-endpoint-subnet --vnet-name azml-aks-online-endpoint-vnet  --address-prefixes 10.0.0.0/22 --network-security-group azml-aks-online-endpoint-nsg

      - name: Get runner IP address
        run: |
            export runner_ip="$(curl -s https://api.ipify.org)"
            echo "runner_ip=$runner_ip" >> $GITHUB_ENV

   #   - name: Get Azure Machine Learning IP range
   #     run: |
   #       export azml_ip_addresses=$

      - name: Create AKS Cluster
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
         SUBNET=$(az network vnet subnet list --resource-group $RESOURCE_GROUP --vnet-name azml-aks-online-endpoint-vnet --query "[?name=='azml-aks-online-endpoint-subnet'].id" --output tsv)
         az aks create \
          --resource-group $RESOURCE_GROUP \
          --name azml-aks-online-endpoint-cluster \
          --load-balancer-sku standard \
          --network-plugin azure \
          --vnet-subnet-id $SUBNET \
          --dns-service-ip 10.2.0.10 \
          --service-cidr 10.2.0.0/24 \
          --enable-managed-identity \
          --generate-ssh-keys \
          --node-vm-size standard_DS3_v2
      #  --api-server-authorized-ip-ranges $runner_ip,20.42.0.240/28,20.62.135.208/28,40.71.11.64/28,40.78.227.32/28,40.79.154.64/28,52.255.214.109/32,52.255.217.127/32,4.171.27.64/27,4.171.27.160/28,4.232.25.0/27,13.66.87.135/32,13.66.140.80/28,13.67.8.224/28,13.69.64.192/28,13.69.106.192/28,13.69.227.192/28,13.70.72.144/28,13.71.170.192/28,13.71.173.80/28,13.71.194.240/28,13.73.240.16/28,13.73.240.112/28,13.73.240.240/28,13.73.248.96/28,13.74.107.160/28,13.75.36.16/28,13.77.50.224/28,13.78.106.208/28,13.86.195.35/32,13.87.56.112/28,13.87.122.112/28,13.87.160.129/32,13.89.171.64/28,20.17.49.0/27,20.17.113.0/27,20.21.33.0/27,20.21.83.64/27,20.36.106.80/28,20.36.114.160/28,20.37.67.80/28,20.37.74.208/28,20.37.152.240/28,20.37.192.96/28,20.38.80.96/28,20.38.128.48/28,20.38.147.128/28,20.39.1.205/32,20.39.11.80/28,20.40.141.171/32,20.40.231.32/28,20.41.0.240/28,20.41.64.80/28,20.41.197.0/28,20.42.0.240/28,20.42.129.16/28,20.42.227.48/28,20.43.40.96/28,20.43.64.96/28,20.43.120.112/28,20.43.128.112/28,20.44.3.32/28,20.44.26.224/28,20.44.132.166/32,20.45.240.64/28,20.46.13.192/28,20.48.197.240/28,20.51.1.48/28,20.51.14.48/28,20.51.21.224/28,20.62.61.128/28,20.62.135.208/28,20.65.135.0/28,20.66.6.48/28,20.69.1.240/28,20.70.216.96/28,20.72.16.48/28,20.74.195.32/27,20.82.244.0/28,20.86.88.160/28,20.89.9.0/28,20.98.195.64/27,20.99.8.96/27,20.150.161.128/28,20.150.171.80/28,20.150.179.64/28,20.150.187.64/28,20.150.246.16/28,20.188.219.157/32,20.188.221.15/32,20.189.106.80/28,20.189.229.176/28,20.192.47.112/28,20.192.99.64/28,20.192.160.48/28,20.192.225.144/28,20.192.235.16/28,20.193.194.176/28,20.195.69.64/28,20.195.75.48/28,20.195.75.96/27,20.200.192.16/28,20.210.146.32/27,20.213.226.160/28,20.215.1.0/27,20.215.174.32/27,20.217.41.0/27,23.98.82.192/28,23.100.232.216/32,40.66.61.146/32,40.67.59.80/28,40.69.106.224/28,40.70.146.192/28,40.70.154.161/32,40.71.11.64/28,40.74.24.96/28,40.74.100.176/28,40.74.147.48/28,40.75.35.48/28,40.78.194.224/28,40.78.202.80/28,40.78.227.32/28,40.78.234.128/28,40.78.242.176/28,40.78.250.112/28,40.79.130.192/28,40.79.138.128/28,40.79.146.128/28,40.79.154.64/28,40.79.162.48/28,40.79.170.224/28,40.79.178.224/28,40.79.186.160/28,40.79.194.64/28,40.80.51.64/28,40.80.57.176/28,40.80.169.160/28,40.80.184.80/28,40.80.188.96/28,40.81.27.228/32,40.82.187.230/32,40.82.248.80/28,40.89.17.208/28,40.90.184.249/32,40.91.77.76/32,40.112.242.176/28,40.119.8.80/28,51.11.24.49/32,51.12.29.0/28,51.12.29.64/27,51.12.47.32/28,51.12.99.80/28,51.12.198.224/28,51.12.203.80/28,51.12.227.64/28,51.12.235.64/28,51.53.25.0/27,51.53.169.0/27,51.104.8.64/27,51.104.24.96/28,51.105.67.16/28,51.105.75.128/28,51.105.88.224/28,51.105.129.135/32,51.107.59.48/28,51.107.147.32/28,51.107.155.48/28,51.107.247.64/27,51.116.49.176/28,51.116.59.48/28,51.116.155.112/28,51.116.156.128/28,51.116.250.224/28,51.120.99.64/28,51.120.107.64/28,51.120.211.64/28,51.120.219.80/28,51.120.227.80/28,51.120.234.224/28,51.137.161.224/28,51.138.213.16/28,51.140.146.208/28,51.140.210.208/28,51.143.214.32/28,51.144.184.47/32,52.138.90.144/28,52.138.226.160/28,52.139.3.33/32,52.140.107.96/28,52.141.25.58/32,52.141.26.97/32,52.148.163.43/32,52.150.136.80/28,52.151.111.249/32,52.155.90.254/32,52.155.115.7/32,52.156.193.50/32,52.162.106.176/28,52.167.106.160/28,52.177.164.219/32,52.182.139.32/28,52.184.87.76/32,52.185.70.56/32,52.228.80.80/28,52.230.56.136/32,52.231.18.192/28,52.231.146.208/28,52.236.186.192/28,52.242.224.215/32,52.246.155.128/28,52.249.59.91/32,52.252.160.26/32,52.253.131.79/32,52.253.131.198/32,52.253.227.208/32,52.255.214.109/32,52.255.217.127/32,65.52.250.192/28,68.221.81.0/27,102.37.163.32/28,102.133.27.32/28,102.133.58.224/28,102.133.122.224/27,102.133.155.32/28,102.133.251.64/28,104.208.16.160/28,104.208.144.160/28,104.211.81.144/28,104.214.19.32/28,108.140.0.224/28,158.23.97.0/27,191.233.8.48/28,191.233.203.144/28,191.233.240.165/32,191.233.242.167/32,191.234.147.64/28,191.234.155.64/28,191.235.224.96/28,191.238.73.80/28 \

      - name: Get KubeConfig
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: az aks get-credentials -g $RESOURCE_GROUP  -n azml-aks-online-endpoint-cluster --overwrite-existing --admin


      - name: Create AZML K8s namespace
        run: kubectl create namespace azml-aks-online-endpoint-ns
      
        
      - name: Install AZ ML CLI Extenstion 
        run: |
            curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash 
            az extension add -n ml -y

      - name: Setup AZML workspace
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          LOCATION: eastus 
        run: |
            az ml workspace create -n $WORKSPACE -g $RESOURCE_GROUP -l $LOCATION
            az configure --defaults group=$RESOURCE_GROUP workspace=$WORKSPACE location=$LOCATION

      - name: Clone model training repository
        run: |
            git clone --depth 1 https://github.com/Azure/azureml-examples
            

      - name: Create JSONL file from downloaded data
        env: 
          AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/
        run: |
          python ./data/jsontojsonl.py --subscription $SUBSCRIPTION_ID --group $RESOURCE_GROUP --workspace $WORKSPACE --data_path ./odFridgeObjects

     
      - name: Create training managed compute - CPU Cluster
        run: |
            az ml compute create -n cpu-cluster --type amlcompute --min-instances 0 --max-instances 4
    
      - name: Create training managed compute - GPU Instance
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/compute
        run: |
            az ml compute create -f gpucompute.yaml  --workspace-name $WORKSPACE --resource-group $RESOURCE_GROUP --subscription $SUBSCRIPTION_ID
    
      - name: Train example model 1
        working-directory: /home/runner/work/azml-aks-online-endpoint/azureml-examples/cli/
        run: |
           export run_id=$(az ml job create -f jobs/single-step/scikit-learn/iris/job.yml --query name -o tsv)
           echo "run_id=$run_id" >> $GITHUB_ENV

      - name: Wait for model 1 job to finish
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export jobstatus=$(az ml job show --name $run_id --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          until [ "$jobstatus" = "Completed" ]; do
            echo "Waiting for job to finish"
            sleep 10
            export jobstatus=$(az ml job show --name $run_id --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          done

      - name: Register model 1
        run: |
          az ml model create -n sklearn-iris-example -v 1 -p runs:/$run_id/model --type mlflow_model

      - name: Train model 2
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/
        run: |
           export run_id_2=$(az ml job create --file ./jobs/automl_automode.yaml --workspace-name $WORKSPACE --resource-group $RESOURCE_GROUP --subscription $SUBSCRIPTION_ID --output json | jq -r .display_name) 
            echo "run_id_2=$run_id_2" >> $GITHUB_ENV

      - name: Wait for model 2 job to finish
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export jobstatus=$(az ml job show --name $run_id_2 --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          until [ "$jobstatus" = "Completed" ]; do
            echo "Waiting for job to finish"
            sleep 10
            export jobstatus=$(az ml job show --name $run_id_2 --query "{Jobstatus:status}"  --output json --resource-group $RESOURCE_GROUP  --workspace-name $WORKSPACE | jq -r .Jobstatus )
          done

      - name: Register model 2
        env:
          WORKSPACE: azml_aks_online_endpoint_ws
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
          az ml model create -n fridge-items-mlflow-model -v 1 -p runs:/"$run_id_2"_HD_4/outputs/mlflow-model --type mlflow_model --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --subscription $SUBSCRIPTION_ID


      - name: Add preview extension
        run: |
          az extension add --name aks-preview
          az extension update --name aks-preview

      - name: Register and install the GPU Extenstion
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
           az feature register --namespace "Microsoft.ContainerService" --name "GPUDedicatedVHDPreview"
           az provider register --namespace Microsoft.ContainerService

      - name: Register and install the Azure ML extension
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
           az k8s-extension create --name azml-aks-online --extension-type Microsoft.AzureML.Kubernetes --config enableTraining=True enableInference=True inferenceRouterServiceType=LoadBalancer allowInsecureConnections=True InferenceRouterHA=False --cluster-type managedClusters --cluster-name azml-aks-online-endpoint-cluster --resource-group $RESOURCE_GROUP --scope cluster

      
      - name: Create AZML K8s instance types CRDS 
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/kubernetes_config
        run: kubectl apply -f instance_types.yaml 
     
      - name: Create GPU Nodepool for Model 1
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
         az aks nodepool add \
         --resource-group $RESOURCE_GROUP \
         --cluster-name azml-aks-online-endpoint-cluster \
         --name gpumodel1 \
         --node-count 1 \
         --node-vm-size standard_nc4as_t4_v3  \
         --labels gpu=yes costcenter=5000 model=model1 \
         --aks-custom-headers UseGPUDedicatedVHD=true \
         --enable-cluster-autoscaler \
         --min-count 1 \
         --max-count 3

      - name: Create GPU Nodepool for Model 2
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
         az aks nodepool add \
         --resource-group $RESOURCE_GROUP \
         --cluster-name azml-aks-online-endpoint-cluster \
         --name gpumodel2 \
         --node-count 1 \
         --node-vm-size standard_nc4as_t4_v3  \
         --labels gpu=yes costcenter=6000 model=model2 \
         --aks-custom-headers UseGPUDedicatedVHD=true \
         --enable-cluster-autoscaler \
         --min-count 1 \
         --max-count 3

      - name: Attatch cluster to ML Workspace
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
         az ml compute attach --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --type Kubernetes --name azml-aks-compute --resource-id "/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.ContainerService/managedclusters/azml-aks-online-endpoint-cluster" --identity-type SystemAssigned --namespace azml-aks-online-endpoint-ns 
     
      - name: Allow attatchment to marinate for 1 minute
        run: |
          sleep 1m

      - name: Create ML Endpoint for model 1 with AKS backend
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/endpoint/
        run: |
          az ml online-endpoint create --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --name azml-aks-online-endpoint-model1 -f model1_endpoint_config.yaml
          az ml online-deployment create --name blue --endpoint azml-aks-online-endpoint-model1 -f model1_kubernetes_deployment.yaml --all-traffic --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE

      - name: Create ML Endpoint for model 2 with AKS backend
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          WORKSPACE: azml_aks_online_endpoint_ws
        working-directory: /home/runner/work/azml-aks-online-endpoint/azml-aks-online-endpoint/azml_files/endpoint/
        run: |
          az ml online-endpoint create --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE --name azml-aks-online-endpoint-model2 -f model2_endpoint_config.yaml
          az ml online-deployment create --name blue --endpoint azml-aks-online-endpoint-model2 -f model2_kubernetes_deployment.yaml --all-traffic --resource-group $RESOURCE_GROUP --workspace-name $WORKSPACE
       
      - name: Create function storage account
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export functionstorage="funcstorage$RANDOM"
          echo "functionstorage=$functionstorage" >> $GITHUB_ENV
          az storage account create --name $functionstorage --location useast --resource-group $RESOURCE_GROUP --sku Standard_LRS --kind StorageV2  --allow-blob-public-access true
    
      - name: Create Azure Function
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          az functionapp create --name azml-function-app-inference --storage-account $functionstorage --resource-group $RESOURCE_GROUP --consumption-plan-location useast
      
      - name: Configure function app storage
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          storageConnectionString=$(az storage account show-connection-string --resource-group $RESOURCE_GROUP --name inferenceupload  --query connectionString --output tsv)
          az functionapp config appsettings set --name azml-function-app-inference --resource-group $RESOURCE_GROUP --settings AzureWebJobsStorage=$storageConnectionString FUNCTIONS_EXTENSION_VERSION=~2 FUNCTIONS_WORKER_RUNTIME=dotnet
     
      - name: Create the Service Bus
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          az servicebus namespace create --resource-group $RESOURCE_GROUP --name azmlaksonlineendpointbus --location eastus --mi-system-assigned
          az servicebus queue create --resource-group $RESOURCE_GROUP --namespace-name azmlaksonlineendpointbus --name azmlaksonlineendpointbusq
       
      - name: Create storage for DLQ
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          storageAccountName: azmlaksonlinedlq 
        run: |
            az storage account create \
             --name $storageAccountName \
             --resource-group $RESOURCE_GROUP \
            --query id \
            --output tsv 1>/dev/null

            echo "Retrieving the primary key of the [$storageAccountName] storage account..."
            export storageAccountKey=$(az storage account keys list \
             --account-name $storageAccountName \
            --resource-group $resourceGroupName \
            --query [0].value -o tsv)
              az storage container create \
             --name azmldlq \
             --account-name $storageAccountName \
              --account-key $storageAccountKey \
            --query id \
            --output tsv 1>/dev/null

      - name: Create eventgrid subscription 
        env: 
         RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          export subjectEndsWith="${tenant,,}"
          export storageAccountId=$(az storage account show \
            --name $storageAccountName \
            --resource-group $resourceGroupName \
            --query id \
            --output tsv 2>/dev/null)

          export serviceBusId=$(az servicebus queue show \
            --name $serviceBusQueueName \
            --namespace-name azmlaksonlineendpointbus \
           --resource-group $RESOURCE_GROUP \
            --query id \
            --output tsv)

          az eventgrid event-subscription create \
            --endpoint-type servicebusqueue \
            --endpoint $serviceBusId \
            --deadletter-endpoint ${storageAccountId}/blobServices/default/containers/azmldlq \
            --name $eventGridSubscriptionName \
            --subject-ends-with $subjectEndsWith \
            --source-resource-id $resourceId 1>/dev/null

      - name: Create system topic for Azure Storage account
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          storageid=$(az storage account show --name inferenceupload --resource-group $RESOURCE_GROUP --query id --output tsv) 
          az eventgrid system-topic create \
          -g $RESOURCE_GROUP \
          --name inference-storage-topic\
          --location useast \
          --topic-type microsoft.storage.storageaccounts \
          --source $storageid
     
     
      - name: Create eventgrid subscription to push to queue 
        env: 
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
          SUBSCRIPTION_ID: ${{ secrets.SUBSCRIPTION_ID }}
        run: |
          az eventgrid event-subscription create --name azml-aks-online-es1 \
          --system-topic-name  \
          --endpoint /subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/namespaces/azmlaksonlineendpointbus/

      - name: Create COSMOS output table
        env:
          RESOURCE_GROUP: azml-aks-online-endpoint-rg
        run: |
          az cosmosdb database create --name azml-aks-online-endpoint-output-db --resource-group $RESOURCE_GROUP --db-name model2output
      
# Create function that is triggered by event hub or service bus
# Create code for function that calls AZML API and uploads result to Cosmos DB
